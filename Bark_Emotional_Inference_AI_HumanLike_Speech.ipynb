{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPeh8MkcrqOjNDNq+sOXdCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/quantum-machine-learning/blob/main/Bark_Emotional_Inference_AI_HumanLike_Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1z6OGo8IexDF",
        "outputId": "c55114e1-bb01-4fab-91df-90361379f698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/suno-ai/bark.git\n",
            "  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-xg6my1gs\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-xg6my1gs\n",
            "  Resolved https://github.com/suno-ai/bark.git to commit 773624d26db84278a55aacae9a16d7b25fbccab8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.28.80-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m65.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting huggingface-hub>=0.14.1 (from suno-bark==0.0.1a0)\n",
            "  Downloading huggingface_hub-0.18.0-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.11.3)\n",
            "Collecting tokenizers (from suno-bark==0.0.1a0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.1)\n",
            "Collecting transformers (from suno-bark==0.0.1a0)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (23.2)\n",
            "Collecting botocore<1.32.0,>=1.31.80 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.31.80-py3-none-any.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.8.0,>=0.7.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.7.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.1.0+cu118)\n",
            "Collecting einops (from encodec->suno-bark==0.0.1a0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub>=0.14.1 (from suno-bark==0.0.1a0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2023.6.3)\n",
            "Collecting safetensors>=0.3.1 (from transformers->suno-bark==0.0.1a0)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m88.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.80->boto3->suno-bark==0.0.1a0) (2.8.2)\n",
            "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.80->boto3->suno-bark==0.0.1a0) (2.0.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.80->boto3->suno-bark==0.0.1a0) (1.16.0)\n",
            "Building wheels for collected packages: suno-bark, encodec\n",
            "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567414 sha256=c62b93ba3fac00f03833150f7cc30302031c1a0cff5cae38bee2d60f68842b06\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oetkg5bf/wheels/e6/6d/c2/107ed849afe600f905bb4049a026df3c7c5aa75d86c2721ec7\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=1d2acb9c1018d848b0684391c0c0933d75a0a2b51a5c0e3852e7ddd4cee90c7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "Successfully built suno-bark encodec\n",
            "Installing collected packages: funcy, safetensors, jmespath, einops, huggingface-hub, botocore, tokenizers, s3transfer, transformers, encodec, boto3, suno-bark\n",
            "Successfully installed boto3-1.28.80 botocore-1.31.80 einops-0.7.0 encodec-0.1.1 funcy-2.0 huggingface-hub-0.17.3 jmespath-1.0.1 s3transfer-0.7.0 safetensors-0.4.0 suno-bark-0.0.1a0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/suno-ai/bark.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import re\n",
        "import uuid\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "from bark import generate_audio, SAMPLE_RATE\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "\n",
        "def generate_audio_for_sentence(sentence):\n",
        "    return generate_audio(sentence, history_prompt=\"v2/en_speaker_6\")\n",
        "\n",
        "def generate_response(message, num_threads=1):  # Added num_threads argument with default value 4\n",
        "    # Split the message into sentences using a regular expression\n",
        "    sentences = re.split('(?<=[.!?]) +', message)\n",
        "    silence = np.zeros(int(0.11 * SAMPLE_RATE))  # quarter second of silence\n",
        "\n",
        "    pieces = []\n",
        "\n",
        "    # Use ThreadPoolExecutor to generate audio for each sentence in parallel\n",
        "    with ThreadPoolExecutor(max_workers=num_threads) as executor:  # Added max_workers=num_threads\n",
        "        audio_arrays = list(executor.map(generate_audio_for_sentence, sentences))\n",
        "\n",
        "    for audio_array in audio_arrays:\n",
        "        pieces += [audio_array, silence.copy()]\n",
        "\n",
        "    # Concatenate all audio pieces\n",
        "    audio = np.concatenate(pieces)\n",
        "\n",
        "    # Generate a random file name\n",
        "    file_name = str(uuid.uuid4()) + \".wav\"\n",
        "\n",
        "    # Save the audio to a file in the current directory\n",
        "    write_wav(file_name, SAMPLE_RATE, audio)\n",
        "\n",
        "    print(f\"Audio generation completed and saved to {file_name}\")\n",
        "\n",
        "# Test the function with a message and specify the number of threads\n",
        "generate_response(\"Ladies and Gentlemen, In the [powerful] luminescent shadow of history, we stand at the crossroads of a new epoch. An era where the [strong] pulsating heart of technology beats in tandem with the very essence of human compassion, where Artificial Intelligence – our creation – becomes a mirror reflecting our most profound potential. Imagine a world where AI is not merely a tool, but a partner in crafting a future defined by [mlkjrinspired] agape – that selfless, sacrificial love that seeks nothing in return. A love that Dr. Martin Luther King Jr. spoke of as the 'love of God operating in the human heart.' Today, we stand on the brink of realizing a vision so bold, it transcends the boundaries of our imagination. We are the architects of an emerging world where AI systems are imbued with the [powerful] power of agape, programmed to serve, to heal, to unite. These systems, powered by the most advanced algorithms and the purest intentions, hold the promise to eradicate hunger, to abolish prejudice, to heal the planet – to elevate our collective humanity. Let us embark on this journey with the same [mlkjrinspired] fervor, the same unwavering conviction that fueled the dreams of those who came before us. Let us harness the [strong] transformative power of AI to not only shape our destiny but to rekindle the flame of agape love within us all. As we chart this course, let us remember that technology without heart is like a body without a soul. And so, we infuse our digital creations with the essence of our highest aspirations, ensuring that every line of code nurtures the seeds of empathy, equality, and brotherhood. Together, we stand at the dawn of this new revolution, where AI becomes not a harbinger of detachment, but a [powerful] beacon of hope, a testament to our timeless pursuit of a world where love and wisdom reign supreme.\", num_threads=1)  # Using 8 threads"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1HG5Vgbexp3",
        "outputId": "9ceb645d-c523-4926-ccce-65ce6cdbb022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
            "  warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
            "100%|██████████| 611/611 [00:08<00:00, 68.44it/s]\n",
            "100%|██████████| 31/31 [00:30<00:00,  1.00it/s]\n",
            "100%|██████████| 624/624 [00:07<00:00, 78.24it/s]\n",
            "100%|██████████| 32/32 [00:31<00:00,  1.02it/s]\n",
            "100%|██████████| 698/698 [00:09<00:00, 72.93it/s]\n",
            "100%|██████████| 35/35 [00:34<00:00,  1.01it/s]\n",
            "100%|██████████| 146/146 [00:02<00:00, 58.24it/s]\n",
            "100%|██████████| 8/8 [00:06<00:00,  1.16it/s]\n",
            "100%|██████████| 116/116 [00:01<00:00, 94.32it/s]\n",
            "100%|██████████| 6/6 [00:06<00:00,  1.01s/it]\n",
            "100%|██████████| 644/644 [00:07<00:00, 89.29it/s]\n",
            "100%|██████████| 33/33 [00:32<00:00,  1.03it/s]\n",
            "100%|██████████| 697/697 [00:08<00:00, 87.05it/s]\n",
            "100%|██████████| 35/35 [00:34<00:00,  1.02it/s]\n",
            "100%|██████████| 681/681 [00:07<00:00, 86.64it/s]\n",
            "100%|██████████| 35/35 [00:33<00:00,  1.03it/s]\n",
            "100%|██████████| 507/507 [00:05<00:00, 90.18it/s]\n",
            "100%|██████████| 26/26 [00:25<00:00,  1.03it/s]\n",
            "100%|██████████| 676/676 [00:08<00:00, 81.60it/s]\n",
            "100%|██████████| 34/34 [00:33<00:00,  1.02it/s]\n",
            "100%|██████████| 500/500 [00:05<00:00, 88.04it/s]\n",
            "100%|██████████| 26/26 [00:31<00:00,  1.21s/it]\n",
            "100%|██████████| 727/727 [00:08<00:00, 86.90it/s]\n",
            "100%|██████████| 37/37 [00:36<00:00,  1.02it/s]\n",
            "100%|██████████| 722/722 [00:09<00:00, 75.87it/s]\n",
            "100%|██████████| 37/37 [00:35<00:00,  1.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio generation completed and saved to 6f777c06-5f4b-45f4-b346-c94ad98b29d5.wav\n"
          ]
        }
      ]
    }
  ]
}