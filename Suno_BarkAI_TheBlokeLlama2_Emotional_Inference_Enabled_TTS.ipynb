{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN8TOBQHbCY/Q0s8d79JUYj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/quantum-machine-learning/blob/main/Suno_BarkAI_TheBlokeLlama2_Emotional_Inference_Enabled_TTS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z6OGo8IexDF"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/suno-ai/bark.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build Llama cpp\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python==0.1.78"
      ],
      "metadata": {
        "id": "4hoHF4vqexkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import llama_cpp\n",
        "from bark import SAMPLE_RATE, generate_audio\n",
        "import numpy as np\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import uuid\n",
        "\n",
        "def llama2_generate_text(prompt):\n",
        "    # Initialize the Llama2 model\n",
        "    llm = llama_cpp.Llama(\n",
        "        model_path=\"llama-2-7b-chat.ggmlv3.q8_0.bin\",\n",
        "        n_gpu_layers=-1,\n",
        "        n_ctx=3900,\n",
        "    )\n",
        "\n",
        "    # Generate the text using the Llama2 model with the input message as a prompt\n",
        "    response = llm(prompt, max_tokens=700)\n",
        "\n",
        "    # Clean up the Llama2 model\n",
        "    del llm\n",
        "\n",
        "    return response['choices'][0]['text']\n",
        "\n",
        "def generate_response(message):\n",
        "    # Use the input message as a prompt for the Llama2 model\n",
        "    prompt = f\"\"\"\n",
        "    1. You are a text-to-speech model called Bark.\n",
        "    2. Analyze the following text: '{message}'\n",
        "    3. Infer emotions from the text.\n",
        "    4. Split the text into meaningful segments.\n",
        "    5. Generate responses for each segment.\n",
        "    6. Include emotional tags in the responses.\n",
        "    7. Re-employ the Llama2 model to double-check the analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    # Analyze the text for emotions and split it into meaningful segments\n",
        "    segments_analysis = llama2_generate_text(prompt).split('\\n')\n",
        "\n",
        "    # Process each segment and generate audio\n",
        "    pieces = []\n",
        "    for segment_analysis in segments_analysis:\n",
        "        try:\n",
        "            segment, emotion = segment_analysis.split(' - Emotion: ')\n",
        "            segment = segment.replace('Segment: ', '').strip()\n",
        "\n",
        "            # Define the emotional tag that Bark can recognize\n",
        "            if emotion.strip() == \"happy\":\n",
        "                emotion_tag = \"[joyful]\"\n",
        "            elif emotion.strip() == \"sad\":\n",
        "                emotion_tag = \"[sad]\"\n",
        "            elif emotion.strip() == \"angry\":\n",
        "                emotion_tag = \"[angry]\"\n",
        "            elif emotion.strip() == \"calm\":\n",
        "                emotion_tag = \"[calm]\"\n",
        "            elif emotion.strip() == \"excited\":\n",
        "                emotion_tag = \"[excited]\"\n",
        "            else:\n",
        "                emotion_tag = \"[neutral]\"\n",
        "\n",
        "            # Generate audio with the specified emotional tag\n",
        "            audio_array = generate_audio(segment + emotion_tag, history_prompt=\"v2/en_speaker_6\")\n",
        "            silence = np.zeros(int(0.75 * SAMPLE_RATE))  # quarter second of silence\n",
        "            pieces += [audio_array, silence.copy()]\n",
        "        except ValueError:\n",
        "            print(f\"Error processing segment: {segment_analysis}\")\n",
        "            continue\n",
        "\n",
        "    # Concatenate all audio pieces\n",
        "    audio = np.concatenate(pieces)\n",
        "\n",
        "    # Generate a random file name\n",
        "    wav_file_name = str(uuid.uuid4()) + \".wav\"\n",
        "\n",
        "    # Save the audio to a WAV file in the current directory\n",
        "    write_wav(wav_file_name, SAMPLE_RATE, audio)\n",
        "\n",
        "    print(f\"Audio file generated: {wav_file_name}\")"
      ],
      "metadata": {
        "id": "l1HG5Vgbexp3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}