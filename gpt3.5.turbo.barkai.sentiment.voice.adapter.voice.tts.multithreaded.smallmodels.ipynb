{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyON8MfIPv+6K1GxYFdvfxEe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/quantum-machine-learning/blob/main/gpt3.5.turbo.barkai.sentiment.voice.adapter.voice.tts.multithreaded.smallmodels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjCBN1fqDsco",
        "outputId": "9845acb2-8d4a-40d0-f192-ab41908fb331"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Collecting git+https://github.com/suno-ai/bark.git\n",
            "  Cloning https://github.com/suno-ai/bark.git to /tmp/pip-req-build-n56xa8fe\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/suno-ai/bark.git /tmp/pip-req-build-n56xa8fe\n",
            "  Resolved https://github.com/suno-ai/bark.git to commit 56b0ba13f7c281cbffa07ea9abf7b30273a60b6a\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting boto3 (from suno-bark==0.0.1a0)\n",
            "  Downloading boto3-1.28.30-py3-none-any.whl (135 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.8/135.8 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting encodec (from suno-bark==0.0.1a0)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting funcy (from suno-bark==0.0.1a0)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Collecting huggingface-hub>=0.14.1 (from suno-bark==0.0.1a0)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (1.10.1)\n",
            "Collecting tokenizers (from suno-bark==0.0.1a0)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from suno-bark==0.0.1a0) (4.66.1)\n",
            "Collecting transformers (from suno-bark==0.0.1a0)\n",
            "  Downloading transformers-4.31.0-py3-none-any.whl (7.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (23.1)\n",
            "Collecting botocore<1.32.0,>=1.31.30 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading botocore-1.31.30-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting s3transfer<0.7.0,>=0.6.0 (from boto3->suno-bark==0.0.1a0)\n",
            "  Downloading s3transfer-0.6.2-py3-none-any.whl (79 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from encodec->suno-bark==0.0.1a0) (2.0.2+cu118)\n",
            "Collecting einops (from encodec->suno-bark==0.0.1a0)\n",
            "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->suno-bark==0.0.1a0) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->suno-bark==0.0.1a0) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->suno-bark==0.0.1a0) (2023.6.3)\n",
            "Collecting safetensors>=0.3.1 (from transformers->suno-bark==0.0.1a0)\n",
            "  Downloading safetensors-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.10/dist-packages (from botocore<1.32.0,>=1.31.30->boto3->suno-bark==0.0.1a0) (2.8.2)\n",
            "Collecting urllib3<1.27,>=1.25.4 (from botocore<1.32.0,>=1.31.30->boto3->suno-bark==0.0.1a0)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->suno-bark==0.0.1a0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.14.1->suno-bark==0.0.1a0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->suno-bark==0.0.1a0) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.32.0,>=1.31.30->boto3->suno-bark==0.0.1a0) (1.16.0)\n",
            "Building wheels for collected packages: suno-bark, encodec\n",
            "  Building wheel for suno-bark (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for suno-bark: filename=suno_bark-0.0.1a0-py3-none-any.whl size=2567430 sha256=0e9eaa5c987f2747d769dbef9331b6d1768b77ae4220f59c50d03b0a376cb456\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_zh3pvx8/wheels/e6/6d/c2/107ed849afe600f905bb4049a026df3c7c5aa75d86c2721ec7\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=f1a5bb56fd5d98b66a3c88dba9dbd9dfb7199f75223379411b9b2a4911613fd1\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "Successfully built suno-bark encodec\n",
            "Installing collected packages: tokenizers, safetensors, funcy, urllib3, jmespath, einops, botocore, s3transfer, huggingface-hub, transformers, boto3, encodec, suno-bark\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.4\n",
            "    Uninstalling urllib3-2.0.4:\n",
            "      Successfully uninstalled urllib3-2.0.4\n",
            "Successfully installed boto3-1.28.30 botocore-1.31.30 einops-0.6.1 encodec-0.1.1 funcy-2.0 huggingface-hub-0.16.4 jmespath-1.0.1 s3transfer-0.6.2 safetensors-0.3.2 suno-bark-0.0.1a0 tokenizers-0.13.3 transformers-4.31.0 urllib3-1.26.16\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html -U\n",
        "!pip install git+https://github.com/suno-ai/bark.git\n",
        "!pip install openai\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import uuid\n",
        "from scipy.io.wavfile import write as write_wav\n",
        "import openai\n",
        "from bark import generate_audio, SAMPLE_RATE\n",
        "import os\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "os.environ[\"SUNO_USE_SMALL_MODELS\"] = \"True\"\n",
        "os.environ[\"SUNO_OFFLOAD_CPU\"] = \"True\"\n",
        "\n",
        "# Initialize OpenAI API with your key\n",
        "openai_api_key = \"getopenaikeyfromhereandputhere;https://platform.openai.com/account/api-keys\"\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "def analyze_and_split_text(input_text):\n",
        "    # Use GPT-3.5 turbo to analyze the input text, infer emotions, and split it into meaningful segments\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model='gpt-3.5-turbo',\n",
        "        messages=[\n",
        "            {'role': 'system', 'content': 'You are an expert in analyzing text and inferring emotions. Analyze the following text and split it into meaningful segments, providing the emotions for each segment. Return the segments in the following format: \"Segment: [text] - Emotion: [emotion]\". Consider the following special features: [laughter] for laughter, [sighs] for sighs, [music] for music, [gasps] for gasps, [clears throat] for clearing throat, ... for hesitations, ♪ for song lyrics, CAPITALIZATION for emphasis, [MAN] for male speakers, and [WOMAN] for female speakers.'},\n",
        "            {'role': 'user', 'content': input_text}\n",
        "        ],\n",
        "    )\n",
        "    return response['choices'][0]['message']['content'].split('\\n')\n",
        "\n",
        "def generate_audio_with_emotion(segment, emotion):\n",
        "    # Map emotions to Bark's special tags\n",
        "    emotion_to_tag = {\n",
        "        'laughter': '[laughter]',\n",
        "        'joy': '[laughs]',\n",
        "        'sadness': '[sighs]',\n",
        "        'music': '[music]',\n",
        "        'surprise': '[gasps]',\n",
        "        'hesitation': '...',\n",
        "        'song': '♪',\n",
        "        'emphasis': 'CAPITALIZATION',\n",
        "        'male': '[MAN]',\n",
        "        'female': '[WOMAN]'\n",
        "    }\n",
        "\n",
        "    # Apply the corresponding tag based on the detected emotion\n",
        "    tag = emotion_to_tag.get(emotion.lower())\n",
        "    if tag:\n",
        "        segment = tag + ' ' + segment\n",
        "\n",
        "    # Generate audio using Bark with the modified text\n",
        "    audio_array = generate_audio(segment, history_prompt=\"v2/en_speaker_6\")\n",
        "    return audio_array\n",
        "\n",
        "def process_segment(segment_analysis):\n",
        "    try:\n",
        "        segment, emotion = segment_analysis.split(' - Emotion: ')\n",
        "        segment = segment.replace('Segment: ', '').strip()\n",
        "        audio_array = generate_audio_with_emotion(segment, emotion.strip())\n",
        "        silence = np.zeros(int(0.75 * SAMPLE_RATE))  # quarter second of silence\n",
        "        return [audio_array, silence.copy()]\n",
        "    except ValueError:\n",
        "        print(f\"Error processing segment: {segment_analysis}\")\n",
        "        return []\n",
        "\n",
        "def generate_response(message):\n",
        "    # Analyze the text for emotions and split it into meaningful segments\n",
        "    segments_analysis = analyze_and_split_text(message)\n",
        "\n",
        "    # Process each segment and generate audio using threading with max 2 threads\n",
        "    pieces = []\n",
        "    with ThreadPoolExecutor(max_workers=14) as executor:\n",
        "        results = list(executor.map(process_segment, segments_analysis))\n",
        "        for result in results:\n",
        "            pieces += result\n",
        "\n",
        "    # Concatenate all audio pieces\n",
        "    audio = np.concatenate(pieces)\n",
        "\n",
        "    # Generate a random file name\n",
        "    wav_file_name = str(uuid.uuid4()) + \".wav\"\n",
        "\n",
        "    # Save the audio to a WAV file in the current directory\n",
        "    write_wav(wav_file_name, SAMPLE_RATE, audio)\n",
        "\n",
        "    print(f\"Audio file generated: {wav_file_name}\")\n",
        "\n",
        "# Test the function with a message\n",
        "generate_response(\"I PITY DA FOOL \")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcCUA0UzDxc-",
        "outputId": "ea8442a4-5a72-46c8-81c8-211290e2c817"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 175/175 [00:05<00:00, 34.93it/s]\n",
            "100%|██████████| 9/9 [00:08<00:00,  1.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio file generated: 496e1584-b9eb-4ab2-a893-38a2142414b6.wav\n"
          ]
        }
      ]
    }
  ]
}