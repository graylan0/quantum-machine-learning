{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMJoibFtIjCHPucB3RINu7c",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/graylan0/quantum-machine-learning/blob/main/Quantum_Machine_Learning_gpt_3_5_turbo_pennylane_Weather_Prediction_Hurricane_Warning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDdjV3TbzSyr",
        "outputId": "a7a454da-ddc2-49b3-b7b8-3f5d5590ee98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pennylane\n",
            "  Downloading PennyLane-0.31.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.24 in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.10.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from pennylane) (3.1)\n",
            "Collecting rustworkx (from pennylane)\n",
            "  Downloading rustworkx-0.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autograd<=1.5 (from pennylane)\n",
            "  Downloading autograd-1.5-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from pennylane) (1.4.4)\n",
            "Collecting semantic-version>=2.7 (from pennylane)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting autoray<=0.6.3,>=0.3.1 (from pennylane)\n",
            "  Downloading autoray-0.6.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.3/48.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from pennylane) (5.3.1)\n",
            "Collecting pennylane-lightning>=0.31 (from pennylane)\n",
            "  Downloading PennyLane_Lightning-0.31.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pennylane) (4.7.1)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from autograd<=1.5->pennylane) (0.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pennylane) (2023.7.22)\n",
            "Installing collected packages: semantic-version, rustworkx, autoray, autograd, pennylane-lightning, pennylane\n",
            "  Attempting uninstall: autograd\n",
            "    Found existing installation: autograd 1.6.2\n",
            "    Uninstalling autograd-1.6.2:\n",
            "      Successfully uninstalled autograd-1.6.2\n",
            "Successfully installed autograd-1.5 autoray-0.6.3 pennylane-0.31.1 pennylane-lightning-0.31.0 rustworkx-0.13.1 semantic-version-2.10.0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2023.7.22)\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.8-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "Successfully installed openai-0.27.8\n"
          ]
        }
      ],
      "source": [
        "!pip install pennylane\n",
        "!pip install requests\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pennylane as qml\n",
        "import requests\n",
        "import sqlite3\n",
        "from datetime import datetime\n",
        "import openai\n",
        "\n",
        "openai_api_key = \"YOUR_OPENAI_API_KEY_HERE\"\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "# Quantum Model\n",
        "class EnhancedQuantumHurricaneModel:\n",
        "    def __init__(self, num_qubits, num_layers):\n",
        "        self.num_qubits = num_qubits\n",
        "        self.num_layers = num_layers\n",
        "        self.dev = qml.device('default.qubit', wires=self.num_qubits)\n",
        "\n",
        "    def quantum_layer(self, params):\n",
        "        for i in range(self.num_qubits):\n",
        "            qml.RY(params[i], wires=i)\n",
        "        for i in range(self.num_qubits - 1):\n",
        "            qml.CNOT(wires=[i, i+1])\n",
        "\n",
        "    def quantum_model(self, params):\n",
        "        for layer in range(self.num_layers):\n",
        "            self.quantum_layer(params[layer])\n",
        "\n",
        "    def encode_weather_data(self, weather_data):\n",
        "        params = [[weather_data['pressure'], weather_data['temperature'], weather_data['humidity']] for _ in range(self.num_layers)]\n",
        "        return params\n",
        "\n",
        "# Fetch Weather Data\n",
        "def fetch_weather_data(location):\n",
        "    api_key = \"YOUR_API_KEY\"\n",
        "    base_url = f\"http://api.openweathermap.org/data/2.5/weather?q={location}&appid={api_key}\"\n",
        "    response = requests.get(base_url)\n",
        "    weather_data = response.json()\n",
        "    return {\n",
        "        'pressure': weather_data['main']['pressure'],\n",
        "        'temperature': weather_data['main']['temp'],\n",
        "        'humidity': weather_data['main']['humidity']\n",
        "    }\n",
        "\n",
        "# Create SQL Table\n",
        "def create_table():\n",
        "    conn = sqlite3.connect('hurricane_predictions.db')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute('''CREATE TABLE IF NOT EXISTS predictions\n",
        "                      (location TEXT, date TEXT, pressure REAL, temperature REAL, humidity REAL, probability REAL)''')\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Store Prediction\n",
        "def store_prediction(location, weather_data, probability):\n",
        "    conn = sqlite3.connect('hurricane_predictions.db')\n",
        "    cursor = conn.cursor()\n",
        "    date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    cursor.execute(\"INSERT INTO predictions (location, date, pressure, temperature, humidity, probability) VALUES (?, ?, ?, ?, ?, ?)\",\n",
        "                   (location, date, weather_data['pressure'], weather_data['temperature'], weather_data['humidity'], probability))\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# Fetch History\n",
        "def fetch_history(location):\n",
        "    conn = sqlite3.connect('hurricane_predictions.db')\n",
        "    cursor = conn.cursor()\n",
        "    cursor.execute(\"SELECT * FROM predictions WHERE location = ?\", (location,))\n",
        "    history = cursor.fetchall()\n",
        "    conn.close()\n",
        "    return history\n",
        "\n",
        "# Analyze History with GPT\n",
        "def analyze_history_with_gpt(location):\n",
        "    history = fetch_history(location)\n",
        "    prompt = f\"Analyze the historical weather data and quantum probabilities for {location}:\\n\"\n",
        "    for record in history:\n",
        "        prompt += f\"Date: {record[1]}, Pressure: {record[2]} hPa, Temperature: {record[3]} K, Humidity: {record[4]}%, Probability: {record[5]}\\n\"\n",
        "    prompt += \"Provide insights and predictions for future weather patterns.\"\n",
        "    response = openai.ChatCompletion.create(model='gpt-3.5-turbo', prompt=prompt)\n",
        "    return response.choices[0].text\n",
        "\n",
        "# Main Function\n",
        "def predict_hurricane(location):\n",
        "    weather_data = fetch_weather_data(location)\n",
        "    qml_model = EnhancedQuantumHurricaneModel(3, 3)  # 3 qubits, 3 layers\n",
        "\n",
        "    params = qml_model.encode_weather_data(weather_data)\n",
        "\n",
        "    @qml.qnode(qml_model.dev)\n",
        "    def circuit(params):\n",
        "        qml_model.quantum_model(params)\n",
        "        return qml.expval(qml.PauliZ(wires=0))  # Measure the expectation value of PauliZ on the first qubit\n",
        "\n",
        "    probability = circuit(params)\n",
        "    store_prediction(location, weather_data, probability)\n",
        "    gpt_response = analyze_history_with_gpt(location)\n",
        "\n",
        "    print(\"Weather Data:\", weather_data)\n",
        "    print(\"Quantum Probability:\", probability)\n",
        "    print(\"GPT Response:\", gpt_response)\n",
        "\n",
        "# Example Usage\n",
        "create_table()\n",
        "location = \"Florida\"\n",
        "predict_hurricane(location)\n"
      ],
      "metadata": {
        "id": "40EOVYR0zTd5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}